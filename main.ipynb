{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import importlib \n",
    "import warnings\n",
    "import urllib3\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Directories and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "importlib.reload(config)\n",
    "\n",
    "from config import DatasetConfig\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(DatasetConfig.PATHS['results'], exist_ok=True)\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# Load the annotations\n",
    "print(\"Loading annotations...\")\n",
    "annotations = pd.read_csv(DatasetConfig.PATHS['csv'])\n",
    "print(\"Annotations shape:\", annotations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_analyzer\n",
    "importlib.reload(data_analyzer)\n",
    "\n",
    "from data_analyzer import DataAnalyzer\n",
    "\n",
    "analyzer = DataAnalyzer(annotations, DatasetConfig.PATHS['results'])\n",
    "analyzer.analyze_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Dataset and Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_generator\n",
    "importlib.reload(data_generator)\n",
    "\n",
    "from data_generator import GlomeruliDataGenerator\n",
    "\n",
    "train_val_df, test_df = train_test_split(annotations, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Dataset splits:\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for each set\n",
    "train_generator = GlomeruliDataGenerator(\n",
    "    train_df, \n",
    "    DatasetConfig.PATHS['base'],\n",
    "    batch_size=DatasetConfig.TRAINING['batch_size'],\n",
    "    image_size=DatasetConfig.TRAINING['image_size']\n",
    ")\n",
    "\n",
    "val_generator = GlomeruliDataGenerator(\n",
    "    val_df,\n",
    "    DatasetConfig.PATHS['base'],\n",
    "    batch_size=DatasetConfig.TRAINING['batch_size'],\n",
    "    image_size=DatasetConfig.TRAINING['image_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = GlomeruliDataGenerator(\n",
    "    test_df,\n",
    "    DatasetConfig.PATHS['base'],\n",
    "    batch_size=DatasetConfig.TRAINING['batch_size'],\n",
    "    image_size=DatasetConfig.TRAINING['image_size'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Data generators created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet.resnet_model_builder as resnet_model_builder\n",
    "importlib.reload(resnet_model_builder)\n",
    "\n",
    "from resnet.resnet_model_builder import ModelBuilder\n",
    "\n",
    "# Create model with input shape\n",
    "model = ModelBuilder.create_model(input_shape=(224, 224, 3))\n",
    "\n",
    "# Print model summary to verify architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import resnet.resnet_model_trainer as resnet_model_trainer\n",
    "importlib.reload(resnet_model_trainer)\n",
    "\n",
    "from resnet.resnet_model_trainer import ModelTrainer\n",
    "\n",
    "# Training code\n",
    "trainer = ModelTrainer(model, train_generator, val_generator, results_dir=DatasetConfig.PATHS['results'])\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_evaluator\n",
    "importlib.reload(model_evaluator)\n",
    "\n",
    "from model_evaluator import ModelEvaluator\n",
    "\n",
    "# Initialize evaluator and perform evaluation\n",
    "print(\"Evaluating model performance...\")\n",
    "evaluator = ModelEvaluator(model, test_generator, DatasetConfig.PATHS['results'])\n",
    "evaluator.evaluate(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import densenet.densenet_model_builder as densenet_model_builder\n",
    "importlib.reload(densenet_model_builder)\n",
    "\n",
    "from densenet.densenet_model_builder import ModelBuilder\n",
    "\n",
    "# Create model with input shape\n",
    "model = ModelBuilder.create_model(input_shape=(224, 224, 3))\n",
    "\n",
    "# Print model summary to verify architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import densenet.densenet_model_trainer as densenet_model_trainer\n",
    "importlib.reload(densenet_model_trainer)\n",
    "\n",
    "from densenet.densenet_model_trainer import ModelTrainer\n",
    "\n",
    "# Training code\n",
    "trainer = ModelTrainer(model, train_generator, val_generator, results_dir=DatasetConfig.PATHS['results'])\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_evaluator\n",
    "importlib.reload(model_evaluator)\n",
    "\n",
    "from model_evaluator import ModelEvaluator\n",
    "\n",
    "# Initialize evaluator and perform evaluation\n",
    "print(\"Evaluating model performance...\")\n",
    "evaluator = ModelEvaluator(model, test_generator, DatasetConfig.PATHS['results'])\n",
    "evaluator.evaluate(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation on New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation\n",
    "importlib.reload(evaluation)\n",
    "from evaluation import ModelPredictor\n",
    "\n",
    "# Define paths\n",
    "model_path = os.path.join('model', 'best_model.keras')\n",
    "evaluation_dir = 'path/to/your/image/folder'\n",
    "\n",
    "# Create predictor and run evaluation\n",
    "predictor = ModelPredictor(\n",
    "    model_path=model_path,\n",
    "    evaluation_dir=evaluation_dir\n",
    ")\n",
    "predictor.predict_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
